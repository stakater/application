# Name of the application.
applicationName: "application"

# These labels will be added on all resources, and you can add additional labels from below on individual resource
labels:
  group: com.stakater.platform
  provider: stakater
  team: stakater

deployment:

  # By default deploymentStrategy is set to rollingUpdate with maxSurge of 25% and maxUnavailable of 25%
  # You can change type to `Recreate` or can uncomment `rollingUpdate` specification and adjust them to your usage.
  strategy:
    type: RollingUpdate
    # rollingUpdate:
    #   maxSurge: 25%
    #   maxUnavailable: 25%
  
  # Reload deployment if configMap/secret updates
  reloadOnChange: true

  # Select nodes to deploy which matches the following labels  
  nodeSelector: {}
    # cloud.google.com/gke-nodepool: default-pool  

  # Init container which runs before the app container
  initContainers: 
  # - name: init-contaner
  #   image: busybox
  #   imagePullPolicy: IfNotPresent
  #   command: ['/bin/sh']    

  # Additional labels for Deployment
  additionalLabels: 
    # key: value
  
  # Additional label added on pod which is used in Service's Label Selector
  podLabels: 
    app: application-name

  # Annotations on deployments
  annotations: {}

  # Additional Pod Annotations added on pod created by this Deployment
  additionalPodAnnotations:
    #key: value
  
  # Annotations for fluentd Configurations 
  fluentdConfigAnnotations:
    # fluentd:
    #   regex: hello
    #   timeFormat: world

  # Replicas to be created
  replicas: 2

  # Secrets used to pull image
  imagePullSecrets: ""

  # Environment variables to be passed to the app container
  env: 
  # - name: ENVIRONMENT
  #   value: "dev"
  
  # Volumes to be added to the pod
  volumes: []
    # - name: config-volume
    #   configMap:        
    #     name: configmap-name
    # - name: secret-volume
    #   secret:        
    #     secretName: secret-name
    # - name: volume-name
    #   emptyDir: {}
    # - name: persistent-volume-name
    #   persistentVolumeClaim:
    #     claimName: claim-name

  # Mount path for Volumes 
  volumeMounts: []
    # - mountPath: /path
    #   name: volume-name

  # Taint tolerations for nodes
  tolerations: []
    # - key: "dedicated"
    #   operator: "Equal"
    #   value: "app"
    #   effect: "NoSchedule" 

  # Image of the app container
  image: 
    repository: repository/image-name
    tag: v1.0.0
    pullPolicy: IfNotPresent

  # Readiness and Liveness probes
  probes:
    readinessProbe:
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
      initialDelaySeconds: 10
      httpGet:
        path: /path
        port: 8080
    livenessProbe:
      failureThreshold: 3
      periodSeconds: 10
      successThreshold: 1
      timeoutSeconds: 1
      initialDelaySeconds: 10
      httpGet:
        path: /path
        port: 8080

  # Resources to be defined for pod
  resources: 
    limits:
      memory: 256Mi
      cpu: 0.5
    requests:
      memory: 128Mi
      cpu: 0.1
  
  # Add additional containers besides init and app containers
  additionalContainers: 
  # - name: sidecar-contaner
  #   image: busybox
  #   imagePullPolicy: IfNotPresent
  #   command: ['/bin/sh']    

  # Security Context for the pod
  securityContext: 
    #fsGroup: 2000  

# Add Storage volumes to the pods
persistence:
  enabled: false
  accessMode: ReadWriteOnce
  ## If defined, storageClass: <storageClass>
  ## If set to "-", storageClass: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClass spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  # existingClaim:
  additionalLabels: {}
    # key: "value"
  annotations: {}
  #  "helm.sh/resource-policy": keep
  
  # storageClass: "-"
  storageSize: 8Gi

# Service object for servicing pods
service:
  additionalLabels: {}
    # expose: "true"

  annotations: {}
    # config.xposer.stakater.com/Domain: stakater.com
    # config.xposer.stakater.com/IngressNameTemplate: '{{.Service}}-{{.Namespace}}'
    # config.xposer.stakater.com/IngressURLPath: /
    # config.xposer.stakater.com/IngressURLTemplate: '{{.Service}}.{{.Namespace}}.{{.Domain}'
    # xposer.stakater.com/annotations: |-
    #   kubernetes.io/ingress.class: external-ingress
    #   ingress.kubernetes.io/rewrite-target: /
    #   ingress.kubernetes.io/force-ssl-redirect: true
  
  ports: []
  # - port: 8080
  #   name: http
  #   protocol: TCP
  #   targetPort: 8080
  # - port: 8081
  #   name: http
  #   protocol: TCP
  #   targetPort: 8081

# Ingress object for exposing services
ingress:
  enabled: false
  
  # Port of the service that serves pods
  servicePort: 8080
  
  # List of host addresses to be exposed by this Ingress
  hosts:
    - chart-example.local
  
  # Add annotations to this Ingress
  annotations: 
    # kubernetes.io/ingress.class: external-ingress
    # ingress.kubernetes.io/rewrite-target: /
    # ingress.kubernetes.io/force-ssl-redirect: true

  # TLS details for this Ingress
  tls:
    # Secrets must be manually created in the namespace.
    # - secretName: chart-example-tls
    #   hosts:
    #     - chart-example.local

# Route object for exposing services (OpenShift only)
route:
  enabled: false

  # Add annotations to this Route
  annotations: {}
    # kubernetes.io/ingress.class: external-ingress
    # ingress.kubernetes.io/rewrite-target: /
    # ingress.kubernetes.io/force-ssl-redirect: true
  
  # Additional labels for this Route
  additionalLabels: {}

  # Host addresses to be exposed by this Route
  host: chart-example.local

  # Port of the service that serves pods
  port:
    targetPort: docker
  to:
    kind: Service
    name: example-service  # Service to route to
    weight: 100            # A number between 0 and 255 that depicts relative weight compared with other targets.

  # TLS Termination strategy
  termination: edge

  # TLS cert details
  tls:
    caCertificate: |-
      ca-certificate base64 string
    certificate: |-
      certificate base64 string
    key: |-
      key base64 string


# Expose Application on Forecastle Dashboard
forecastle:
  enabled: false

  # Add additional labels on Forecastle Custom Resource
  additionalLabels: {}
  
  # URL of the icon for the custom appd
  icon: https://raw.githubusercontent.com/stakater/ForecastleIcons/master/stakater-big.png
  
  # Name of the application to be displayed on the Forecastle Dashboard
  displayName: "application"
  
  # Group for the custom app (default: .Release.Namespace)
  group: ""

  # Add properties to Custom Resource
  properties: {}
  
  # Whether app is network restricted or not
  networkRestricted: false


# Role Based Access Control
rbac:
  enabled: true

  # Service Account to use by pods
  serviceAccount:
    enabled: false
    #name: "my-svc-account"

    # Additional Labels on service account
    additionalLabels:
      # key: value
    
    # Annotations on service account 
    annotations:
      # key: value

  # Create Roles (Namespaced)
  roles: 
  # - name: configmaps
  #   rules:
  #   - apiGroups:
  #     - ""
  #     resources:
  #     - configmaps
  #     verbs:
  #     - get
  # - name: secrets
  #   rules:
  #   - apiGroups:
  #     - ""
  #     resources:
  #     - secrets
  #     verbs:
  #     - get

  # Create ClusterRoles (Clusterwide)
  clusterroles:
  # - name: configmaps
  #   rules:
  #   - apiGroups:
  #     - ""
  #     resources:
  #     - configmaps
  #     verbs:
  #     - get
  # - name: pods
  #   rules:
  #   - apiGroups:
  #     - ""
  #     resources:
  #     - pods
  #     verbs:
  #     - get
  #     - list
  #     - watch

# Additional ConfigMaps  
configMap: {}
  # enabled: true
  # additionalLabels: 
  #   # key: value
  # annotations: 
  #   # key: value
  # files:
  # - nameSuffix: code-config    
  #   data:
  #     key1: value1
  #     key2: value2
  # - nameSuffix: dev-config
  #   data:
  #     key1: value1
  #     key2: value2

# Additional Secrets
secret: {} 
  # enabled: true
  # additionalLabels: 
  #   # key: value
  # annotations: 
  #   # key: value
  # files:    
  # - nameSuffix: credentials
  #   data:
  #     secretKey1: secretValue1
  #     secretKey2: secretValue2
  # - nameSuffix: password
  #   data:
  #     secretKey1: secretValue1
  #     secretKey2: secretValue2

# Service Monitor to collect Prometheus metrices
serviceMonitor:
  enabled: false
  
  # Additional labels
  additionalLabels: {}
  
  # Additional annotations
  annotations: {}

  jobLabel: k8s-app
  
  # List of the endpoints of service from which prometheus will scrape data
  endpoints:
  - interval: 5s
    path: /actuator/prometheus     
    port: web